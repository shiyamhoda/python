{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f31cc4a9",
      "metadata": {
        "id": "f31cc4a9"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "687131d2",
      "metadata": {},
      "source": [
        "## Contents:\n",
        "1. Testing\n",
        "2. Writing a test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a700ac7",
      "metadata": {
        "id": "3a700ac7"
      },
      "source": [
        "## Why are tests an integral part of coding?\n",
        "\n",
        "- We should always consider how the code needs to be tested when writing it\n",
        "  - Impact and risk (code authority) vs. cost of testing\n",
        "    - When using rm *.txt, it’s easy to double-check for typos and run ls *.txt first\n",
        "    - It’s probably not worth writing an entire testing program with SOPs\n",
        "    - Using ls *.txt is very low risk, so might decide to run first and check that way\n",
        "  - Which parts of the code need more focus?\n",
        "  - What are edge/unexpected cases that the code might need to handle?\n",
        "  - Testing the code’s ability to gracefully and accurately handle errors\n",
        "\n",
        "## What are the two common paradigms for testing?\n",
        "\n",
        "1. Test-Driven Development\n",
        "2. Checking-driven development"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2894c294",
      "metadata": {},
      "source": [
        "### Test-Driven Development\n",
        "\n",
        "- Rather than writing code and then writing tests, we write tests first and then write just enough code to make them pass\n",
        "- Advocates claim that it leads to better code because:\n",
        "  - Writing tests clarifies what the code is supposed to do.\n",
        "  - It eliminates confirmation bias.\n",
        "  - If someone has just written a function, they are predisposed to want it to be\n",
        "  right, so they will bias their tests towards proving that it is correct instead of trying to uncover errors.\n",
        "  - Writing tests first ensures that they get written."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a9eba20",
      "metadata": {},
      "source": [
        "### Checking-driven development\n",
        "\n",
        "- Writing just a few lines of code and testing it before moving on rather than writing several pages of code and then spending hours on testing\n",
        "- For example: every time we add a step to our pipeline\n",
        "  - Look at its output\n",
        "  - Write a test or check of some kind to the pipeline\n",
        "  - Ensure that what we are checking remains true if it were run on other data or if the pipeline evolves"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53d496c7",
      "metadata": {},
      "source": [
        "# Writing a test\n",
        "\n",
        "Let's say we have a function called `is_even_number`, which check to see if a number is an even number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4c3de3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_even_number(number):\n",
        "  return number % 2 == 0\n",
        "\n",
        "print(is_even_number(2234234324)) # True\n",
        "print(is_even_number(5646453)) # False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3402884",
      "metadata": {},
      "source": [
        "How can we check that the behaviour be what we expect it to do `True` or `False` if the code changes in the future? We can test that out manually, but we would have to do that infinite times! That is super long and by the time we retired, we would still be computing for the answer.\n",
        "\n",
        "This is where we want to write tests using assertions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5d10cf6",
      "metadata": {},
      "source": [
        "### What are assertions?\n",
        "\n",
        "Assert is a built-in Python keyword we use to assert something is `True` confidently, especially when we are debugging. It looks like this:\n",
        "\n",
        "```python\n",
        "assert\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f3a42f17",
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_even_number(number):\n",
        "  return number % 2 == 0\n",
        "\n",
        "# They will not print out. But if you run it and you get a checkmark, then all the tests passes!\n",
        "assert is_even_number(2342323434)\n",
        "assert is_even_number(34345643) == False\n",
        "\n",
        "# This will fail and raise an AssertionError, because assert always expects True. To satisify that statement, we need to put it as a condition as seen above\n",
        "#  assert is_even_number(34345643)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "collapsed_sections": [
        "0294d7fe",
        "b3f69e98",
        "cd134d80",
        "16f27979",
        "f1caca54",
        "3a700ac7",
        "722d2c13",
        "ed8b70b9"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "rise": {
      "scroll": true,
      "theme": "solarized",
      "transition": "none"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
